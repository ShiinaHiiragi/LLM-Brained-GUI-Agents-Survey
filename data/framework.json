[
    {
        "Name": "Web Agents with World Models: Learning and Leveraging Environment Dynamics in Web Navigation",
        "Platform": "Web",
        "Date": "October 2024",
        "Paper_Url": "http://arxiv.org/abs/2410.13232v1",
        "Highlight": "Uses a world model to predict state changes before committing actions, improving task success rates and minimizing unnecessary interactions with the environment",
        "Code_Url": "https://github.com/kyle8581/WMA-Agents"
    },
    {
        "Name": "A Real-World WebAgent with Planning, Long Context Understanding, and Program Synthesis",
        "Platform": "Web",
        "Date": "July 2023",
        "Paper_Url": "http://arxiv.org/abs/2307.12856v4",
        "Highlight": "Leverages specialized LLMs to achieve HTML-based task planning and programmatic action execution",
        "Code_Url": "/"
    },
    {
        "Name": "LASER: LLM Agent with State-Space Exploration for Web Navigation",
        "Platform": "Web",
        "Date": "September 2023",
        "Paper_Url": "http://arxiv.org/abs/2309.08172v2",
        "Highlight": "Uses a state-space exploration approach, allowing it to handle novel situations with flexible backtracking",
        "Code_Url": "https://github.com/Mayer123/LASER"
    },
    {
        "Name": "WebVoyager: Building an End-to-End Web Agent with Large Multimodal Models",
        "Platform": "Web",
        "Date": "January 2024",
        "Paper_Url": "http://arxiv.org/abs/2401.13919v4",
        "Highlight": "Integrates visual and textual cues within real-world, rendered web pages, enhancing its ability to navigate complex web structures",
        "Code_Url": "https://github.com/MinorJerry/WebVoyager"
    },
    {
        "Name": "AutoWebGLM: A Large Language Model-based Web Navigating Agent",
        "Platform": "Web",
        "Date": "April 2024",
        "Paper_Url": "https://arxiv.org/abs/2404.03648",
        "Highlight": "Its HTML simplification method for efficient webpage comprehension and its bilingual benchmark",
        "Code_Url": "https://github.com/THUDM/AutoWebGLM"
    },
    {
        "Name": "OpenAgents: An Open Platform for Language Agents in the Wild",
        "Platform": "Web",
        "Date": "October 2023",
        "Paper_Url": "http://arxiv.org/abs/2310.10634v1",
        "Highlight": "Democratizes access to language agents by providing an open-source, multi-agent framework optimized for real-world tasks",
        "Code_Url": "https://github.com/xlang-ai/OpenAgents"
    },
    {
        "Name": "GPT-4V(ision) is a Generalist Web Agent, if Grounded",
        "Platform": "Web",
        "Date": "January 2024",
        "Paper_Url": "http://arxiv.org/abs/2401.01614v2",
        "Highlight": "Its use of GPT-4V's multimodal capabilities to integrate both visual and HTML information, allowing for more accurate task performance on dynamic web content",
        "Code_Url": "https://github.com/OSU-NLP-Group/SeeAct"
    },
    {
        "Name": "Dual-View Visual Contextualization for Web Navigation",
        "Platform": "Web",
        "Date": "February 2024",
        "Paper_Url": "http://arxiv.org/abs/2402.04476v2",
        "Highlight": "Dual-view contextualization",
        "Code_Url": "/"
    },
    {
        "Name": "Agent-E: From Autonomous Web Navigation to Foundational Design Principles in Agentic Systems",
        "Platform": "Web",
        "Date": "July 2024",
        "Paper_Url": "http://arxiv.org/abs/2407.13032v1",
        "Highlight": "Hierarchical architecture and adaptive DOM perception",
        "Code_Url": "https://github.com/EmergenceAI/Agent-E"
    },
    {
        "Name": "Tree Search for Language Model Agents",
        "Platform": "Web",
        "Date": "July 2024",
        "Paper_Url": "http://arxiv.org/abs/2407.01476v2",
        "Highlight": "Novel inference-time search algorithm that enhances the agent\u2019s ability to perform multi-step planning and decision-making",
        "Code_Url": "https://jykoh.com/search-agents"
    },
    {
        "Name": "WebPilot: A Versatile and Autonomous Multi-Agent System for Web Task Execution with Strategic Exploration",
        "Platform": "Web",
        "Date": "August 2024",
        "Paper_Url": "http://arxiv.org/abs/2408.15978v1",
        "Highlight": "Dual optimization strategy (Global and Local) with Monte Carlo Tree Search (MCTS), allowing dynamic adaptation to complex, real-world web environments",
        "Code_Url": "https://yaoz720.github.io/WebPilot/"
    },
    {
        "Name": "Beyond Browsing: API-Based Web Agents",
        "Platform": "Web",
        "Date": "October 2024",
        "Paper_Url": "http://arxiv.org/abs/2410.16464v1",
        "Highlight": "Hybrid Agent seamlessly integrates web browsing and API calls",
        "Code_Url": "https://github.com/yueqis/API-Based-Agent"
    },
    {
        "Name": "AgentOccam: A Simple Yet Strong Baseline for LLM-Based Web Agents",
        "Platform": "Web",
        "Date": "October 2024",
        "Paper_Url": "http://arxiv.org/abs/2410.13825v1",
        "Highlight": "Simple design that optimizes the observation and action spaces",
        "Code_Url": "/"
    },
    {
        "Name": "NNetscape Navigator: Complex Demonstrations for Web Agents Without a Demonstrator",
        "Platform": "Web",
        "Date": "October 2024",
        "Paper_Url": "http://arxiv.org/abs/2410.02907v1",
        "Highlight": "Trains web agents using synthetic demonstrations, eliminating the need for expensive human input",
        "Code_Url": "https://github.com/MurtyShikhar/Nnetnav"
    },
    {
        "Name": "NaviQAte: Functionality-Guided Web Application Navigation",
        "Platform": "Web",
        "Date": "September 2024",
        "Paper_Url": "http://arxiv.org/abs/2409.10741v1",
        "Highlight": "Frames web navigation as a question-and-answer task",
        "Code_Url": "/"
    },
    {
        "Name": "OpenWebAgent: An Open Toolkit to Enable Web Agents on Large Language Models",
        "Platform": "Web",
        "Date": "August 2024",
        "Paper_Url": "https://aclanthology.org/2024.acl-demos.8/",
        "Highlight": "Modular design that allows developers to seamlessly integrate various models to automate web tasks",
        "Code_Url": "https://github.com/THUDM/OpenWebAgent/"
    },
    {
        "Name": "Steward: Natural Language Web Automation",
        "Platform": "Web",
        "Date": "September 2024",
        "Paper_Url": "http://arxiv.org/abs/2409.15441v1",
        "Highlight": "Ability to automate web interactions using natural language instructions",
        "Code_Url": "/"
    },
    {
        "Name": "Is Your LLM Secretly a World Model of the Internet? Model-Based Planning for Web Agents",
        "Platform": "Web",
        "Date": "November 2024",
        "Paper_Url": "http://arxiv.org/abs/2411.06559v1",
        "Highlight": "Pioneers the use of LLMs as world models for planning in complex web environments",
        "Code_Url": "https://github.com/OSU-NLP-Group/WebDreamer"
    },
    {
        "Name": "Agent Q: Advanced Reasoning and Learning for Autonomous AI Agents",
        "Platform": "Web",
        "Date": "August 2024",
        "Paper_Url": "http://arxiv.org/abs/2408.07199v1",
        "Highlight": "Combination of MCTS-guided search and self-critique mechanisms enables iterative improvement in reasoning and task execution",
        "Code_Url": "https://github.com/sentient-engineering/agent-q"
    },
    {
        "Name": "VisionTasker: Mobile Task Automation Using Vision Based UI Understanding and LLM Task Planning",
        "Platform": "Android",
        "Date": "December 2023",
        "Paper_Url": "http://arxiv.org/abs/2312.11190v2",
        "Highlight": "Vision-based UI understanding approach, which allows it to interpret UI semantics directly from screenshots without view hierarchy dependencies",
        "Code_Url": "https://github.com/AkimotoAyako/VisionTasker"
    },
    {
        "Name": "DroidBot-GPT: GPT-powered UI Automation for Android",
        "Platform": "Android",
        "Date": "April 2023.",
        "Paper_Url": "http://arxiv.org/abs/2304.07061v5",
        "Highlight": "Automates Android applications without modifications to either the app or the model",
        "Code_Url": "https://github.com/MobileLLM/DroidBot-GPT"
    },
    {
        "Name": "CoCo-Agent: A Comprehensive Cognitive MLLM Agent for Smartphone GUI Automation",
        "Platform": "Android",
        "Date": "February 2024",
        "Paper_Url": "http://arxiv.org/abs/2402.11941v3",
        "Highlight": "Its dual approach of Comprehensive Environment Perception and Conditional Action Prediction",
        "Code_Url": "https://github.com/xbmxb/CoCo-Agent"
    },
    {
        "Name": "You Only Look at Screens: Multimodal Chain-of-Action Agents",
        "Platform": "Android",
        "Date": "September 2023",
        "Paper_Url": "http://arxiv.org/abs/2309.11436v4",
        "Highlight": "Its direct interaction with GUI elements. Its chain-of-action mechanism enables it to leverage both past and planned actions",
        "Code_Url": "https://github.com/cooelf/Auto-GUI"
    },
    {
        "Name": "GPT-4V in Wonderland: Large Multimodal Models for Zero-Shot Smartphone GUI Navigation",
        "Platform": "IOS and Android",
        "Date": "November 2023",
        "Paper_Url": "http://arxiv.org/abs/2311.07562v1",
        "Highlight": "Using set-of-mark prompting with GPT-4V for precise GUI navigation on smartphones",
        "Code_Url": "https://github.com/zzxslp/MM-Navigator"
    },
    {
        "Name": "AppAgent: Multimodal Agents as Smartphone Users",
        "Platform": "Android",
        "Date": "December 2023",
        "Paper_Url": "http://arxiv.org/abs/2312.13771v2",
        "Highlight": "Its ability to perform tasks on any smartphone app using a human-like interaction method",
        "Code_Url": "https://appagent-official.github.io/"
    },
    {
        "Name": "AppAgent v2: Advanced Agent for Flexible Mobile Interactions",
        "Platform": "Android",
        "Date": "August 2024",
        "Paper_Url": "http://arxiv.org/abs/2408.11824v3",
        "Highlight": "Enhances adaptability and precision in mobile environments by combining structured data parsing with visual features",
        "Code_Url": "/"
    },
    {
        "Name": "ScreenAgent: A Vision Language Model-driven Computer Control Agent",
        "Platform": "Linux and Windows",
        "Date": "February 2024",
        "Paper_Url": "http://arxiv.org/abs/2402.07945v1",
        "Highlight": "Integrated planning-acting-reflecting pipeline that simulates a continuous thought process",
        "Code_Url": "https://github.com/niuzaisheng/ScreenAgent"
    },
    {
        "Name": "AutoDroid: LLM-powered Task Automation in Android",
        "Platform": "Android",
        "Date": "August 2023",
        "Paper_Url": "http://arxiv.org/abs/2308.15272v4",
        "Highlight": "Its use of app-specific knowledge and a multi-granularity query optimization module to reduce the computational cost",
        "Code_Url": "https://autodroid-sys.github.io/"
    },
    {
        "Name": "Android in the Zoo: Chain-of-Action-Thought for GUI Agents",
        "Platform": "Android",
        "Date": "March 2024",
        "Paper_Url": "http://arxiv.org/abs/2403.02713v2",
        "Highlight": "The integration of a chain-of-action-thought process, which explicitly maps each action to screen descriptions, reasoning steps, and anticipated outcomes",
        "Code_Url": "https://github.com/IMNearth/CoAT"
    },
    {
        "Name": "Mobile-Agent: Autonomous Multi-Modal Mobile Device Agent with Visual Perception",
        "Platform": "Android",
        "Date": "January 2024",
        "Paper_Url": "http://arxiv.org/abs/2401.16158v2",
        "Highlight": "Vision-centric approach that eliminates dependency on system-specific data",
        "Code_Url": "https://github.com/X-PLUG/MobileAgent"
    },
    {
        "Name": "Mobile-Agent-v2: Mobile Device Operation Assistant with Effective Navigation via Multi-Agent Collaboration",
        "Platform": "Android and Harmony",
        "Date": "June 2024",
        "Paper_Url": "http://arxiv.org/abs/2406.01014v1",
        "Highlight": "Multi-agent architecture enhances task navigation for long-sequence operations",
        "Code_Url": "https://github.com/X-PLUG/MobileAgent"
    },
    {
        "Name": "MobileExperts: A Dynamic Tool-Enabled Agent Team in Mobile Devices",
        "Platform": "Android",
        "Date": "July 2024",
        "Paper_Url": "http://arxiv.org/abs/2407.03913v1",
        "Highlight": "Code-combined tool formulation method and double-layer planning mechanism for collaborative task execution",
        "Code_Url": "/"
    },
    {
        "Name": "Lightweight Neural App Control",
        "Platform": "Android",
        "Date": "October 2024",
        "Paper_Url": "https://arxiv.org/abs/2410.17883",
        "Highlight": "Balances computational efficiency and natural language understanding",
        "Code_Url": "/"
    },
    {
        "Name": "MobA: A Two-Level Agent System for Efficient Mobile Task Automation",
        "Platform": "Android",
        "Date": "October 2024",
        "Paper_Url": "http://arxiv.org/abs/2410.13757v1",
        "Highlight": "Two-level agent system that separates task planning and execution into two specialized agents",
        "Code_Url": "https://github.com/OpenDFM/MobA"
    },
    {
        "Name": "UFO: A UI-Focused Agent for Windows OS Interaction",
        "Platform": "Windows",
        "Date": "February 2024",
        "Paper_Url": "https://arxiv.org/abs/2402.07939",
        "Highlight": "Its dual-agent system that seamlessly navigates and interacts with multiple applications to fulfill complex user requests in natural language on Windows OS",
        "Code_Url": "https://github.com/microsoft/UFO"
    },
    {
        "Name": "OS-Copilot: Towards Generalist Computer Agents with Self-Improvement",
        "Platform": "Linux and MacOS",
        "Date": "February 2024",
        "Paper_Url": "http://arxiv.org/abs/2402.07456v2",
        "Highlight": "Self-directed learning capability, allowing it to adapt to new applications by autonomously generating and refining tools",
        "Code_Url": "https://os-copilot.github.io/"
    },
    {
        "Name": "Cradle: Empowering Foundation Agents Towards General Computer Control",
        "Platform": "Windows",
        "Date": "March 2024",
        "Paper_Url": "http://arxiv.org/abs/2403.03186v3",
        "Highlight": "Its generalizability across various digital environments, allowing it to operate without relying on internal APIs",
        "Code_Url": "https://baai-agents.github.io/Cradle/"
    },
    {
        "Name": "Agent S: An Open Agentic Framework that Uses Computers Like a Human",
        "Platform": "Ubuntu and Windows",
        "Date": "October 2024",
        "Paper_Url": "http://arxiv.org/abs/2410.08164v1",
        "Highlight": "Experience-augmented hierarchical planning",
        "Code_Url": "https://github.com/simular-ai/Agent-S"
    },
    {
        "Name": "GUI Action Narrator: Where and When Did That Action Take Place?",
        "Platform": "Windows",
        "Date": "June 2024",
        "Paper_Url": "http://arxiv.org/abs/2406.13719v1",
        "Highlight": "Uses the cursor as a focal point to improve understanding of high-resolution GUI actions",
        "Code_Url": "https://showlab.github.io/GUI-Narrator"
    },
    {
        "Name": "A Zero-Shot Language Agent for Computer Control with Structured Reflection",
        "Platform": "Computer",
        "Date": "October 2023",
        "Paper_Url": "http://arxiv.org/abs/2310.08740v3",
        "Highlight": "Zero-shot capability in performing computer control tasks",
        "Code_Url": "https://github.com/google-research/google-research/tree/master/zero_shot_structured_reflection"
    },
    {
        "Name": "AutoGLM: Autonomous Foundation Agents for GUIs",
        "Platform": "Web and Android",
        "Date": "October 2024",
        "Paper_Url": "http://arxiv.org/abs/2411.00820v1",
        "Highlight": "Self-evolving online curriculum RL framework, which enables continuous improvement by interacting with real-world environments",
        "Code_Url": "https://xiao9905.github.io/AutoGLM/"
    },
    {
        "Name": "TinyClick: Single-Turn Agent for Empowering GUI Automation",
        "Platform": "Web, Mobile, and Windows",
        "Date": "October 2024",
        "Paper_Url": "http://arxiv.org/abs/2410.11871v2",
        "Highlight": "Compact size (0.27B parameters) with high performance",
        "Code_Url": "https://huggingface.co/Samsung/TinyClick"
    },
    {
        "Name": "OSCAR: Operating System Control via State-Aware Reasoning and Re-Planning",
        "Platform": "Computer and Mobile",
        "Date": "October 2024",
        "Paper_Url": "http://arxiv.org/abs/2410.18963v1",
        "Highlight": "Ability to adapt to real-time feedback and dynamically adjust its actions",
        "Code_Url": "/"
    },
    {
        "Name": "AgentStore: Scalable Integration of Heterogeneous Agents As Specialized Generalist Computer Assistant",
        "Platform": "Computer and Mobile",
        "Date": "October 2024",
        "Paper_Url": "http://arxiv.org/abs/2410.18603v1",
        "Highlight": "Dynamically integrate a wide variety of heterogeneous agents, enabling both specialized and generalist capabilities",
        "Code_Url": "https://chengyou-jia.github.io/AgentStore-Home/"
    },
    {
        "Name": "MMAC-Copilot: Multi-modal Agent Collaboration Operating System Copilot",
        "Platform": "Windows, Mobile applications, and game environments",
        "Date": "April 2024",
        "Paper_Url": "http://arxiv.org/abs/2404.18074v2",
        "Highlight": "Collaborative multi-agent architecture where agents specialize in specific tasks",
        "Code_Url": "/"
    },
    {
        "Name": "Auto-Intent",
        "Platform": "Web",
        "Date": "October 2024",
        "Paper_Url": "https://arxiv.org/abs/2410.22552",
        "Highlight": "Introduces a unique self-exploration strategy to generate semantically diverse intent hints",
        "Code_Url": ""
    },
    {
        "Name": "AdaptAgent",
        "Platform": "Web",
        "Date": "November 2024",
        "Paper_Url": "https://arxiv.org/abs/2411.13451",
        "Highlight": "Adapts to unseen tasks with just 1–2 multimodal human demonstrations",
        "Code_Url": ""
    },
    {
        "Name": "MobileGPT",
        "Platform": "Android",
        "Date": "December 2023",
        "Paper_Url": "https://arxiv.org/pdf/2312.03003",
        "Highlight": "Uses task decomposition and external memory to reduce reduce cost and latency",
        "Code_Url": "https://mobile-gpt.github.io/"
    },
    {
        "Name": "Aguvis: Unified Pure Vision Agents for Autonomous GUI Interaction",
        "Platform": "Web, Desktop, and Mobile",
        "Date": "December 2024",
        "Paper_Url": "https://arxiv.org/abs/2412.04454",
        "Highlight": "Pure vision-based approach for GUI interaction, bypassing textual UI representations and enabling robust cross-platform generalization",
        "Code_Url": "https://aguvis-project.github.io"
    },
    {
        "Name": "ScribeAgent: Towards Specialized Web Agents Using Production-Scale Workflow Data",
        "Platform": "Web",
        "Date": "November 2024",
        "Paper_Url": "https://arxiv.org/abs/2411.15004",
        "Highlight": "Specialized fine-tuning approach using production-scale workflow data to outperform general-purpose LLMs like GPT-4 in web navigation tasks",
        "Code_Url": "https://github.com/colonylabs/ScribeAgent"
    },
    {
        "Name": "Ponder & Press: Advancing Visual GUI Agent towards General Computer Control",
        "Platform": "Web, Android, iOS Mobile, Windows, and macOS",
        "Date": "December 2024",
        "Paper_Url": "https://arxiv.org/abs/2412.01268",
        "Highlight": "Divide-and-conquer architecture & purely vision-based GUI agent that does not require non-visual inputs",
        "Code_Url": "https://invinciblewyq.github.io/ponder-press-page/"
    },
    {
        "Name": "Proposer-Agent-Evaluator (PAE): Autonomous Skill Discovery For Foundation Model Internet Agents",
        "Platform": "Web",
        "Date": "December 2024",
        "Paper_Url": "https://arxiv.org/abs/2412.01268",
        "Highlight": "Autonomous skill discovery in real-world environments using task proposers and reward-based evaluation",
        "Code_Url": "https://yanqval.github.io/PAE/"
    },
    {
        "Name": "PC Agent: While You Sleep, AI Works -- A Cognitive Journey into Digital World",
        "Platform": "Windows",
        "Date": "December 2024",
        "Paper_Url": "https://arxiv.org/abs/2412.17589",
        "Highlight": "Human cognition transfer framework, which transforms raw interaction data into cognitive trajectories to enable complex computer tasks.",
        "Code_Url": "https://invinciblewyq.github.io/ponder-press-page/"
    },
    {
        "Name": "WEPO: Web Element Preference Optimization for LLM-based Web Navigation",
        "Platform": "Web",
        "Date": "December 2024",
        "Paper_Url": "https://arxiv.org/abs/2412.10742",
        "Highlight": "Incorporates a distance-based sampling mechanism tailored to the DOM tree structure, enhancing preference learning by distinguishing between salient and non-salient web elements with DPO",
        "Code_Url": ""
    },
    {
        "Name": "AutoDroid-V2: Boosting SLM-based GUI Agents via Code Generation",
        "Platform": "Android",
        "Date": "December 2024",
        "Paper_Url": "https://arxiv.org/abs/2412.18116",
        "Highlight": "Converts GUI task automation into a script generation problem, enhancing efficiency and task success rates.",
        "Code_Url": ""
    },
    {
        "Name": "Mobile-Agent-E: Self-Evolving Mobile Assistant for Complex Tasks",
        "Platform": "Android",
        "Date": "January 2025",
        "Paper_Url": "https://arxiv.org/abs/2501.11733",
        "Highlight": "Hierarchical multi-agent framework that separates planning from execution for improved long-term reasoning and self-evolution, enabling the system to learn reusable tips and shortcuts.",
        "Code_Url": "https://x-plug.github.io/MobileAgent"
    },
    {
        "Name": "Learn-by-interact: A Data-Centric Framework for Self-Adaptive Agents in Realistic Environments",
        "Platform": "Web, code development, and desktops",
        "Date": "January 2025",
        "Paper_Url": "https://arxiv.org/abs/2501.10893",
        "Highlight": "Introduces a fully autonomous data synthesis process, eliminating the need for human-labeled agentic data.",
        "Code_Url": ""
    },
    {
        "Name": "R2D2: Remembering, Reflecting and Dynamic Decision Making for Web Agents",
        "Platform": "Web",
        "Date": "January 2025",
        "Paper_Url": "https://arxiv.org/abs/2501.12485",
        "Highlight": "Dynamically constructs an internal web environment representation for more robust decision-making. The integration of a replay buffer and error analysis reduces navigation errors and improves task completion rates.",
        "Code_Url": "https://github.com/AmenRa/retriv"
    },
    {
        "Name": "ClickAgent: Enhancing ui location capabilities of autonomous agents",
        "Platform": "Android",
        "Date": "October 2024",
        "Paper_Url": "https://arxiv.org/abs/2410.11872",
        "Highlight": "Combines MLLM reasoning with a dedicated UI location model to enhance UI interaction accuracy.",
        "Code_Url": "https://github.com/Samsung/ClickAgent"
    },
    {
        "Name": "ReachAgent: Enhancing Mobile Agent via Page Reaching and Operation",
        "Platform": "Android",
        "Date": "February 2025",
        "Paper_Url": "https://arxiv.org/abs/2502.02955",
        "Highlight": "Divides tasks into subtasks: ``Page Reaching'' (navigating to the correct screen) and ``Page Operation'' (performing actions on the screen), using RL with preference-based training to improve long-term task success.",
        "Code_Url": ""
    },
    {
        "Name": "FedMobileAgent: Training Mobile Agents Using Decentralized Self-Sourced Data from Diverse Users",
        "Platform": "Android",
        "Date": "February 2025",
        "Paper_Url": "https://arxiv.org/abs/2502.02982",
        "Highlight": "Introduces privacy-preserving federated learning for mobile automation, enabling large-scale training without centralized human annotation.",
        "Code_Url": ""
    },
    {
        "Name": "Prompt2Task: Automating UI Tasks on Smartphones from Textual Prompts",
        "Platform": "Android",
        "Date": "February 2025",
        "Paper_Url": "https://dl.acm.org/doi/abs/10.1145/3716132",
        "Highlight": "Enables UI automation through free-form textual prompts, eliminating the need for users to script automation tasks.",
        "Code_Url": "Https://github.com/PromptRPA/Prompt2TaskDataset"
    },
    {
        "Name": "Symbiotic Cooperation for Web Agents: Harnessing Complementary Strengths of Large and Small LLMs",
        "Platform": "Web",
        "Date": "February 2025",
        "Paper_Url": "https://arxiv.org/abs/2502.07942",
        "Highlight": "Multi-agent iterative architecture & Introduces an iterative, symbiotic learning process between large and small LLMs for web automation. Enhances both data synthesis and task performance through speculative data synthesis, multi-task learning, and privacy-preserving hybrid modes.",
        "Code_Url": ""
    },
    {
        "Name": "PC-Agent: A Hierarchical Multi-Agent Collaboration Framework for Complex Task Automation on PC",
        "Platform": "Windows computers",
        "Date": "February 2025",
        "Paper_Url": "https://arxiv.org/abs/2502.14282",
        "Highlight": "PC-Agent's hierarchical multi-agent design enables efficient decomposition of complex PC tasks. Its Active Perception Module enhances fine-grained GUI understanding by combining accessibility structures, OCR, and intention grounding.",
        "Code_Url": "https://github.com/X-PLUG/MobileAgent/tree/main/PC-Agent"
    },
    {
        "Name": "Mobile-Agent-V: Learning Mobile Device Operation Through Video-Guided Multi-Agent Collaboration",
        "Platform": "Android",
        "Date": "February 2025",
        "Paper_Url": "https://arxiv.org/abs/2502.17110",
        "Highlight": " Introduces video-guided learning, allowing the agent to acquire operational knowledge efficiently.",
        "Code_Url": "https://github.com/X-PLUG/MobileAgent"
    },
    {
        "Name": "MobileSteward: Integrating Multiple App-Oriented Agents with Self-Evolution to Automate Cross-App Instructions",
        "Platform": "Android",
        "Date": "February 2025",
        "Paper_Url": "https://arxiv.org/abs/2502.16796",
        "Highlight": "Introduces an app-oriented multi-agent framework with self-evolution, overcoming the complexity of cross-app interactions by dynamically recruiting specialized agents.",
        "Code_Url": "https://github.com/XiaoMi/MobileSteward"
    },
    {
        "Name": "Programming with Pixels: Computer-Use Meets Software Engineering",
        "Platform": "Computers",
        "Date": "February 2025",
        "Paper_Url": "https://arxiv.org/abs/2502.18525",
        "Highlight": "Shifts software engineering agents from API-based tool interactions to direct GUI-based computer use, allowing agents to interact with an IDE as a human developer would.",
        "Code_Url": "https://programmingwithpixels.com"
    },
    {
        "Name": "AppAgentX: Evolving GUI Agents as Proficient Smartphone Users",
        "Platform": "Mobile Android",
        "Date": "March 2025",
        "Paper_Url": "https://arxiv.org/abs/2503.02268",
        "Highlight": "Introduces an evolutionary mechanism that enables dynamic learning from past interactions and replaces inefficient low-level operations with high-level actions.",
        "Code_Url": "https://appagentx.github.io/"
    },
    {
        "Name": "LiteWebAgent: The Open-Source Suite for VLM-Based Web-Agent Applications",
        "Platform": "Web",
        "Date": "March 2025",
        "Paper_Url": "https://arxiv.org/abs/2503.02950",
        "Highlight": "First open-source, production-ready web agent integrating tree search for multi-step task execution.",
        "Code_Url": "https://github.com/PathOnAI/LiteWebAgent"
    },
    {
        "Name": "CHOP: Mobile Operating Assistant with Constrained High-frequency Optimized Subtask Planning",
        "Platform": "Mobile Android",
        "Date": "March 2025",
        "Paper_Url": "https://arxiv.org/abs/2503.03743",
        "Highlight": "Introduces a basis subtask framework, where subtasks are predefined based on human task decomposition patterns, ensuring better executability and efficiency.",
        "Code_Url": "https://github.com/Yuqi-Zhou/CHOP"
    },
    {
        "Name": "Enhancing Language Multi-Agent Learning with Multi-Agent Credit Re-Assignment for Interactive Environment Generalization",
        "Platform": "Mobile Android, Web",
        "Date": "February 2025",
        "Paper_Url": "https://arxiv.org/abs/2502.14496",
        "Highlight": "A multi-agent reinforcement learning framework that introduces a Credit Re-Assignment (CR) strategy, using LLMs instead of environment-specific rewards to enhance performance and generalization.",
        "Code_Url": "https://github.com/THUNLP-MT/CollabUIAgents"
    },
    {
        "Name": "Automating the enterprise with foundation models",
        "Platform": "Web",
        "Date": "May 2024",
        "Paper_Url": "https://arxiv.org/abs/2405.03710",
        "Highlight": "Eliminates the high setup costs, brittle execution, and burdensome maintenance associated with traditional RPA by learning from video and text documentation.",
        "Code_Url": "https://github.com/HazyResearch/eclair-agents"

    },
    {
        "Name": "Towards Ethical and Personalized Web Navigation Agents: A Framework for User-Aligned Task Execution",
        "Platform": "Web",
        "Date": "March 2025",
        "Paper_Url": "https://dl.acm.org/doi/abs/10.1145/3701551.3707420",
        "Highlight": "User-aligned task execution, where the agent adapts to individual user preferences in an ethical manner.",
        "Code_Url": "/"
    },
    {
        "Name": "COLA: A Scalable Multi-Agent Framework For Windows UI Task Automation",
        "Platform": "Windows computers",
        "Date": "March 2025",
        "Paper_Url": "https://arxiv.org/abs/2503.09263",
        "Highlight": "Introduces a dynamic task scheduling mechanism with a plug-and-play agent pool, enabling adaptive handling of GUI tasks.",
        "Code_Url": "https://github.com/Alokia/COLA-demo"
    },
    {
        "Name": "Plan-and-Act: Improving Planning of Agents for Long-Horizon Tasks",
        "Platform": "Web",
        "Date": "March 2025",
        "Paper_Url": "https://arxiv.org/abs/2503.09572",
        "Highlight": "Decouples planning from execution in LLM-based GUI agents and introduces a scalable synthetic data generation pipeline to fine-tune each component.",
        "Code_Url": ""
    },
    {
        "Name": "OS-Kairos: Adaptive Interaction for MLLM-Powered GUI Agents",
        "Platform": "Mobile Android",
        "Date": "March 2025",
        "Paper_Url": "https://arxiv.org/abs/2503.16465",
        "Highlight": "Introduces an adaptive interaction framework where each GUI action is paired with a confidence score, dynamically deciding between autonomous execution and human intervention.",
        "Code_Url": "https://github.com/Wuzheng02/OS-Kairos"
    },
    {
        "Name": "STEVE: AStep Verification Pipeline for Computer-use Agent Training",
        "Platform": "Windows Desktop",
        "Date": "March 2025",
        "Paper_Url": "https://arxiv.org/abs/2503.12532",
        "Highlight": "Introduces a scalable step verification pipeline using GPT-4o to generate binary labels for agent actions, and applies KTO optimization to incorporate both positive and negative actions into agent learning.",
        "Code_Url": "https://github.com/FanbinLu/STEVE"
    },
    {
        "Name": "V-Droid: Advancing Mobile GUI Agents: A Verifier-Driven Approach to Practical Deployment",
        "Platform": "Mobile Android",
        "Date": "March 2025",
        "Paper_Url": "https://arxiv.org/abs/2503.15937",
        "Highlight": "Introduces a novel verifier-driven architecture where the LLM does not generate actions directly but instead scores and selects from a finite set of extracted actions, improving task success rates and significantly reducing latency.",
        "Code_Url": ""
    },
    {
        "Name": "SkillWeaver: Web Agents can Self-Improve by Discovering and Honing Skills",
        "Platform": "Web",
        "Date": "April 2025",
        "Paper_Url": "https://arxiv.org/abs/2504.07079",
        "Highlight": "Introduces a self-improvement framework for web agents that autonomously discover, synthesize, and refine reusable skill APIs through exploration.",
        "Code_Url": "https://github.com/OSU-NLP-Group/SkillWeaver"
    },
    {
        "Name": "Inducing Programmatic Skills for Agentic Tasks",
        "Platform": "Web",
        "Date": "April 2025",
        "Paper_Url": "https://arxiv.org/abs/2504.06821",
        "Highlight": "Introduces programmatic skills that are verified through execution to ensure quality and are used as callable actions to improve efficiency.",
        "Code_Url": "https://github.com/zorazrw/agent-skill-induction"
    },
    {
        "Name": "Enhancing Web Agents with Explicit Rollback Mechanisms",
        "Platform": "Web",
        "Date": "April 2025",
        "Paper_Url": "https://arxiv.org/abs/2504.11788",
        "Highlight": "Introduces a modular rollback mechanism that enables multi-step rollback to avoid dead-end states.",
        "Code_Url": ""
    },
    {
        "Name": "LearnAct: Few-Shot Mobile GUI Agent with a Unified Demonstration Benchmark",
        "Platform": "Mobile Android",
        "Date": "April 2025",
        "Paper_Url": "https://arxiv.org/abs/2504.13805",
        "Highlight": "Introduces a structured, demonstration-based learning pipeline for mobile GUI agents. It addresses long-tail generalization via few-shot demonstrations, achieving substantial performance gains on complex real-world mobile tasks.",
        "Code_Url": "https://lgy0404.github.io/LearnAct"
    },
    {
        "Name": "Agent S2: A Compositional Generalist-Specialist Framework for Computer Use Agents",
        "Platform": "Ubuntu, Windows, Android",
        "Date": "April 2025",
        "Paper_Url": "https://arxiv.org/abs/2504.00906",
        "Highlight": "Features a Mixture of Grounding technique and Proactive Hierarchical Planning, enabling more accurate grounding and adaptive replanning in long-horizon tasks.",
        "Code_Url": "https://github.com/simular-ai/Agent-S"
    },
    {
        "Name": "Guiding VLM Agents with Process Rewards at Inference Time for GUI Navigation",
        "Platform": "Android and Web",
        "Date": "April 2025",
        "Paper_Url": "https://arxiv.org/abs/2504.16073",
        "Highlight": "Introduces a novel process reward model that provides fine-grained, step-level feedback to enhance GUI task accuracy and success.",
        "Code_Url": ""
    },
    {
        "Name": "UFO2: The Desktop AgentOS",
        "Platform": "Windows desktops",
        "Date": "April 2025",
        "Paper_Url": "https://arxiv.org/abs/2504.14603",
        "Highlight": "Transforms a conventional CUA into an OS-native, pluggable AgentOS with deep Windows integration, hybrid GUI–API actions, vision + UIA perception, speculative multi-action planning, retrieval-augmented knowledge, and a non-intrusive PiP virtual desktop.",
        "Code_Url": "https://github.com/microsoft/UFO/"
    }
    

]